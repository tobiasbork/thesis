% Main chapter title
\chapter{Hauptkomponentenanalyse}

% Chapter label
\label{pca}

\section{Motivation}

Heutzutage gibt es viele unstrukturierte Daten. 
Wir wollen Informationen aus diesen Daten gewinnen und Strukturen in den Daten erkennen. Bei der Hauptachsenanalyse wird Informationsgewinn durch Varianzzuwachs gekennzeichnet

WORT WÖRTLICH VON WEBSITE: Hauptkomponentenanalyse analysiert einen Datensatz mit verschiedenen abhängigen Variablen, die in der Regel interkorreliert sind. Ziel ist es, die wichtigste Information des Datensatzes zu extrahieren und diese Information in Form einer geringeren Anzahl an Variablen, den Hauptkomponenten, auszudrücken, die einen Großteil der Varianz des ursprünglichen Datensatzes erklären.

VON WIKIPEDIA (sinnlich übernommen)
Mit der Hauptkomponentenanalyse können umfangreiche Datensätze strukturiert, veranschaulicht und vereinfacht werden.
WORT WÖRTLICH:
Der zugrundeliegende Datensatz hat typischerweise die Struktur einer Matrix: An ${\displaystyle n}n$ Versuchspersonen oder Gegenständen wurden jeweils ${\displaystyle p}p$ Merkmale gemessen. Ein solcher Datensatz kann als Menge von ${\displaystyle n}n$ Punkten im ${\displaystyle p}p$-dimensionalen Raum ${\displaystyle \mathbb {R} ^{p}}\mathbb {R} ^{p}$ veranschaulicht werden. Ziel der Hauptkomponentenanalyse ist es, diese Datenpunkte so in einen ${\displaystyle q}q$-dimensionalen Unterraum ${\displaystyle \mathbb {R} ^{q}}\mathbb {R} ^{q}$ (${\displaystyle q<p}q<p$) zu projizieren, dass dabei möglichst wenig Information verloren geht und vorliegende Redundanz in Form von Korrelation in den Datenpunkten zusammengefasst wird.

Die Hauptkomponentenanalyse ist ein weitverbreites multivariates statistisches Verfahren zur Dimensionsreduktion.
Ein paar Beispiele (hand written zip code classification or human face recognition).
Die zentrale Idee der Hauptkomponentenanalyse besteht darin, die bestehenden Variablen in neue, unkorrelierte Variablen zu überführen, die möglichst den gleichen Informationsgehalt vorweisen. Mit Information ist an dieser Stelle die Varianz gemeint, d.h. man versucht dass diese neue Variablen sich aus Linearkombinationen der Alten zusammensetzen, so dass ein möglichst hoher Grad an Varianz beibehalten werden kann. Die eigentliche Dimensionsreduktion findet dann durch Selektierung der wichtigsten neuen Variablen statt. So erhalten wir einen Datensatz mit meist deutlich weniger Variablen / Dimension, die aber trotzdem den Großteil an Informationen / Varianz beinhaltet.

Das Problem kann auf mehrere Weisen betrachtet werden. Wir wollen zunächst die Hauptkomponentenanalyse so konstruieren und formulieren, dass die Varianzmaximierung im Vordergrund steht. Anschließend werden wir das Problem auf ein Singulärwertzerlegung zurückführen, die auch bei der Implementierung der Funktion genutzt wird. Zu guter letzt werden wir die Hauptkomponentenanalyse als Regressionsproblem umschreiben, und die geometrische Interpretation verdeutlichen. Ausgehend von der geometrischen Interpretation werden wir im nächsten Kapitel die Variante der dünnbesetzten Hauptkomponentenanalyse beschreiben. Des Weiteren werden wir die Äquivalenz dieser Formulierungen und einige theoretische Aussagen zeigen.

Wie müssen die Daten aufbereitet sein? Zentriert und skaliert? Erklären verschiedener Methoden. Korrelationsmatrix oder Kovarianzmatrix?

\section{Konstruktion}

\section{Problemformulierung}
\subsection{Formulierung als Singulärwertzerlegung}
\subsection{Formulierung als Regressionsproblem}
\subsection{Formulierung als beste lineare Mannigfaltigkeit Approximation}

\section{Theoretische Aussagen}